{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd5b0833",
   "metadata": {},
   "source": [
    "# Data Analysis\n",
    "2023-March-03, NSYSU, Exp. course \n",
    "\n",
    "[lecture homepage](https://github.com/baobabyoo/Lecture_DataAnalysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7d21f7",
   "metadata": {},
   "source": [
    "## Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c771f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, time\n",
    "\n",
    "sys.path\n",
    "sys.path.append('./')\n",
    "\n",
    "import numpy as np\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('PDF')\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db93b1d",
   "metadata": {},
   "source": [
    "## Defining functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90078589",
   "metadata": {},
   "outputs": [],
   "source": [
    "def myline(x, a, b):\n",
    "    '''\n",
    "    A function to return y = ax + b\n",
    "    \n",
    "    Input:\n",
    "        x [double] : the x-axis coordinate \n",
    "        a [double] : slope of a 1st order polynomial\n",
    "        b [double] : offset of a 1st order polynomial\n",
    "        \n",
    "    Return:\n",
    "        y [double] : the y-axis value\n",
    "    '''\n",
    "    y = a * x + b\n",
    "    \n",
    "    return y\n",
    "\n",
    "def gaussian_1d(x, amp, x0, sigma):\n",
    "    '''\n",
    "    Return a Gaussian distribution that is normalized to 1.0\n",
    "             \n",
    "    Input:\n",
    "        x [double]       : offset\n",
    "        amp [double]     : amplitude\n",
    "        x0 [double]      : central position of the Gaussian\n",
    "        sigma [double]   : standard deviation of the Gaussian\n",
    "            \n",
    "    Return:\n",
    "        [double]   : A 1-dim Gaussian function\n",
    "    '''\n",
    "    \n",
    "    A = 1.0 / (sigma * np.sqrt(2.0 * np.pi))\n",
    "    \n",
    "    xdiff = x - x0    \n",
    "    B = -0.5 * (( xdiff/sigma )**2.0)\n",
    "\n",
    "    return amp * A * np.exp(B)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de10ba9",
   "metadata": {},
   "source": [
    "## 1. Plotting (A look at 1D Gaussian random variable and uniform random variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2631be86",
   "metadata": {},
   "source": [
    "### 1.1 Producing some data to plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e731b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_x = 300\n",
    "x = np.arange(num_x)\n",
    "\n",
    "mu     = 10.0\n",
    "sigma  = 3.0\n",
    "y_gaus = np.random.normal(loc=mu, scale=sigma, size=num_x)\n",
    "\n",
    "low    = -8.0\n",
    "high   = 2.0\n",
    "y_unif = np.random.uniform(low=low, high=high, size=num_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4940b38b",
   "metadata": {},
   "source": [
    "### 1.2 Plotting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe62c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing Figure ############################################\n",
    "fig = plt.figure(\n",
    "                 figsize = (8, 8)\n",
    "                )\n",
    "ax = fig.add_axes([0.12, 0.1, 0.75, 0.75])\n",
    "\n",
    "# Set the x/y axis title and legend\n",
    "plt.xlabel('x-axis [arbitrary unit]', size = 14.0)\n",
    "plt.ylabel('y-axis [arbitrary unit]', size = 14.0)\n",
    "\n",
    "plt.xscale('linear')\n",
    "plt.yscale('linear')\n",
    "plt.rc('font', size=14.0)          # controls default text sizes\n",
    "plt.rc('xtick', labelsize=14.0)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=14.0)    # fontsize of the tick labels\n",
    "##################################################################\n",
    "\n",
    "plt.plot(\n",
    "    x,\n",
    "    y_gaus,\n",
    "    'o', # symbol shape\n",
    "    color=(0.2,0.3,0.6, 0.7), # (R, G, B, transparency), ranged between [0, 1]\n",
    "    markersize=2, \n",
    "    label = \"Gaussian random variable\"\n",
    "        )\n",
    "\n",
    "plt.plot(\n",
    "    x,\n",
    "    y_unif,\n",
    "    'o', # symbol shape\n",
    "    color=(0.7,0.7,0.2, 0.3), # (R, G, B, transparency), ranged between [0, 1]\n",
    "    markersize=3, \n",
    "    label = \"Uniform random variable\"\n",
    "        )\n",
    "\n",
    "# Setting the figure legend \n",
    "plt.legend(loc=1, fontsize=12)\n",
    "\n",
    "# Setting the plot range\n",
    "plt.xlim( (-20, num_x) )\n",
    "plt.ylim( (-10, 20) )\n",
    "\n",
    "# PDF file output\n",
    "plt.savefig('Gaussian_random_xy.pdf', \n",
    "            transparent = True\n",
    "           )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca19192f",
   "metadata": {},
   "source": [
    "### 1.3 plotting histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fa4aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing Figure ############################################\n",
    "fig = plt.figure(\n",
    "                 figsize = (8, 8)\n",
    "                )\n",
    "ax = fig.add_axes([0.12, 0.1, 0.75, 0.75])\n",
    "\n",
    "# Set the x/y axis title and legend\n",
    "plt.xlabel('x-axis [arbitrary unit]', size = 14.0)\n",
    "plt.ylabel('Counts', size = 14.0)\n",
    "\n",
    "plt.xscale('linear')\n",
    "plt.yscale('linear')\n",
    "plt.rc('font', size=14.0)          # controls default text sizes\n",
    "plt.rc('xtick', labelsize=14.0)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=14.0)    # fontsize of the tick labels\n",
    "##################################################################\n",
    "\n",
    "bins = np.arange(-10, 20, 0.5)\n",
    "\n",
    "\n",
    "plt.hist(y_gaus, \n",
    "         bins=bins, color=(0.2,0.3,0.6, 0.7),\n",
    "         label = \"Gaussian random variable\"\n",
    "        )\n",
    "\n",
    "plt.hist(y_unif, \n",
    "         bins=bins, color=(0.7,0.7,0.2, 0.3),\n",
    "         label = \"Uniform random variable\"\n",
    "        )\n",
    "\n",
    "# Setting the figure legend \n",
    "plt.legend(loc=1, fontsize=12)\n",
    "\n",
    "# PDF file output\n",
    "plt.savefig('Gaussian_random_histogram.pdf', \n",
    "            transparent = True\n",
    "           )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf54af54",
   "metadata": {},
   "source": [
    "## 2. Data I/O"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81af7677",
   "metadata": {},
   "source": [
    "### 2.1 Generating data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbecc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_x = num_x\n",
    "low   = 0\n",
    "high  = 100\n",
    "x = np.random.uniform(low=low, high=high, size=num_x)\n",
    "\n",
    "#a       = 10.0\n",
    "#b       = 100.0\n",
    "a_true  = 10.0\n",
    "b_true  = 100.0\n",
    "sigma_y = 30.0\n",
    "\n",
    "y_err = np.random.normal(loc=0, scale=sigma_y, size=num_x)\n",
    "y     = myline(x, a_true, b_true) + y_err\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b55d4cd",
   "metadata": {},
   "source": [
    "### 2.2 Standard data output, and data input with numpy.loadtxt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a8a9e9",
   "metadata": {},
   "source": [
    "#### 2.2.1 Standard file output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89e94a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'data_1dpoly.txt'\n",
    "\n",
    "# remove the file in case it exist\n",
    "os.system('rm -rf '+ filename)\n",
    "\n",
    "# open output file\n",
    "f = open(filename, \"w\")\n",
    "\n",
    "for i in range(0,num_x):\n",
    "    out_string = str(x[i]) + ' ' + str(y[i]) + ' '  +  str(sigma_y) +'\\n' # '\\n is a line break'\n",
    "    f.write(out_string)\n",
    "\n",
    "# close output file\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96dac611",
   "metadata": {},
   "source": [
    "#### 2.2.2 Read space-separated values using numpy.loadtxt method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce767265",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, y_err = np.loadtxt(filename, \n",
    "                  usecols=(0, 1, 2),\n",
    "                  unpack = True\n",
    "                 )\n",
    "print (\"##### Loaded x values\")\n",
    "print(x)\n",
    "print(' ')\n",
    "print (\"##### Loaded y values\")\n",
    "print(y)\n",
    "print(' ')\n",
    "print (\"##### Loaded y errors\")\n",
    "print(y_err)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4210b684",
   "metadata": {},
   "source": [
    "### 2.3 Data I/O with pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f8de58",
   "metadata": {},
   "source": [
    "#### 2.3.1 Creating a pandas dataframe and output to comma-separated-values files (csv files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d301105",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'x': x,\n",
    "        'y': y,\n",
    "        'y_err': np.zeros(len(y)) + sigma_y\n",
    "       }\n",
    "df = pd.DataFrame(data)\n",
    "print(df)\n",
    "\n",
    "filename = 'data_1dpoly.csv'\n",
    "os.system('rm -rf ' + filename)\n",
    "df.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a63c19a",
   "metadata": {},
   "source": [
    "### 2.3.2 Reading back the csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd573d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './'\n",
    "df_read = pd.read_csv(path + filename)\n",
    "\n",
    "print(df_read)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f66ba07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# examining the read x-values and y-values\n",
    "print(df_read.x)\n",
    "print(' ')\n",
    "print(df_read.y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a38e8b",
   "metadata": {},
   "source": [
    "#### 2.3.3 Plotting the loaded data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653f2772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing Figure ############################################\n",
    "fig = plt.figure(\n",
    "                 figsize = (8, 8)\n",
    "                )\n",
    "ax = fig.add_axes([0.12, 0.1, 0.75, 0.75])\n",
    "\n",
    "# Set the x/y axis title and legend\n",
    "plt.xlabel('x-axis [arbitrary unit]', size = 14.0)\n",
    "plt.ylabel('y-axis [arbitrary unit]', size = 14.0)\n",
    "\n",
    "plt.xscale('linear')\n",
    "plt.yscale('linear')\n",
    "#plt.xscale('linear')\n",
    "#plt.yscale('linear')\n",
    "plt.rc('font', size=14.0)          # controls default text sizes\n",
    "plt.rc('xtick', labelsize=14.0)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=14.0)    # fontsize of the tick labels\n",
    "##################################################################\n",
    "\n",
    "plt.plot(x, y,\n",
    "         'o', markersize = 2.0,\n",
    "         color = (0.7, 0.3, 0.3, 0.7),\n",
    "         label = \"Randomly realized linear model\"\n",
    "        )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367fd17b",
   "metadata": {},
   "source": [
    "## 3. Data modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03e6a80",
   "metadata": {},
   "source": [
    "### Defining functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d715025",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chisquare(y, y_err, ymodel):\n",
    "    '''\n",
    "    Return the chi-square given the measurements of y, y-error, and a model of the measurements y.\n",
    "    \n",
    "    Input:\n",
    "        y [np array]      : measurements\n",
    "        y_err [np array]  : measurement errors\n",
    "        ymodel [np array] : a model of y \n",
    "    \n",
    "    Return:\n",
    "        chisquare [double] : the chi-square value\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    return np.sum( ( (y - ymodel) / y_err)**2 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499bddae",
   "metadata": {},
   "source": [
    "### 3.1 A demonstration of the Metropolis-Hasting algorithm\n",
    "Using a Mexican hat distribution function as an example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658a089d",
   "metadata": {},
   "source": [
    "#### 3.1.1 Defining a Mexican hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d57270",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mexhat(a):\n",
    "    '''\n",
    "    A Mexican hat function.\n",
    "    \n",
    "    Input:\n",
    "      a [double]: the a variable.\n",
    "      \n",
    "    Return:\n",
    "      probability [double]: probability\n",
    "    '''\n",
    "    \n",
    "    if a >= 1.5:\n",
    "        return 0.0\n",
    "    elif a < -1.5:\n",
    "        return 0.0\n",
    "    elif ( \n",
    "             (a <= 1.5) and (a > 0.5)\n",
    "            ):\n",
    "        return 0.25\n",
    "    elif ( \n",
    "             (a >= -1.5) and (a < -0.5)\n",
    "            ):\n",
    "        return 0.25\n",
    "    elif ( \n",
    "             (a >= -0.5) and (a <= 0.5)\n",
    "            ):\n",
    "        return 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fbc9934",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the mexican hat (normalizing peak to 1.0)\n",
    "\n",
    "fig = plt.figure(\n",
    "                 figsize = (8, 8)\n",
    "                )\n",
    "ax = fig.add_axes([0.12, 0.1, 0.75, 0.75])\n",
    "\n",
    "# Set the x/y axis title and legend\n",
    "plt.xlabel('x-axis [arbitrary unit]', size = 14.0)\n",
    "plt.ylabel('probability [arbitrary unit]', size = 14.0)\n",
    "\n",
    "plt.xscale('linear')\n",
    "plt.yscale('linear')\n",
    "plt.rc('font', size=14.0)          # controls default text sizes\n",
    "plt.rc('xtick', labelsize=14.0)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=14.0)    # fontsize of the tick labels\n",
    "\n",
    "a = np.arange(-3, 3, 0.05)\n",
    "y = np.zeros(len(a))\n",
    "for i in range(0, len(a)):\n",
    "    y[i] = mexhat(a[i])\n",
    "\n",
    "plt.plot(a, y/np.max(y), '-',\n",
    "         color = (0.4, 0.4, 1, 1), linewidth = 2.0,\n",
    "         label = 'Mexican hat model'\n",
    "        )\n",
    "\n",
    "# Setting the figure legend \n",
    "plt.legend(loc=2, fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe48d42",
   "metadata": {},
   "source": [
    "#### 3.2.2 Defining proposal distribution, acceptance probability, and Metropolis-Hasting algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3d2e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def proposal_dis(a2, a1):\n",
    "    '''\n",
    "    Here I simply use an unnormalized flat distribution, i.e., given a1,\n",
    "    the probability of making transition to any a2 is a constant. \n",
    "    Here just return 1.0 since the contribution in the dominator/numeritor will cancel.\n",
    "    '''\n",
    "    return 1.0\n",
    "\n",
    "def acceptance_prob(a2, a1):\n",
    "    '''\n",
    "    Given the present a-value (a1) and the next a-vavlue (a2),\n",
    "    evaluate the acceptance probability alpha and return it.\n",
    "    \n",
    "    Input:\n",
    "        a1, a2 [double]: parameter values\n",
    "        \n",
    "    Return:\n",
    "        acceptance probability\n",
    "    '''\n",
    "    numerator =  mexhat(a2) * proposal_dis(a1, a2)\n",
    "    denominator = mexhat(a1)* proposal_dis(a2, a1)\n",
    "    if denominator > 0:\n",
    "        test  = ( mexhat(a2)*proposal_dis(a1, a2) ) / ( mexhat(a1)* proposal_dis(a2, a1))\n",
    "        alpha = np.min([1, test])\n",
    "    else:\n",
    "        alpha = 1.0\n",
    "    return alpha\n",
    "    \n",
    "def metropolis_hasting_flatproposal(a1):\n",
    "    '''\n",
    "    Metropolis-Hasting algorithm. Providing an input a-value,\n",
    "    return the next a-value. Assuming that hte proposal distribution is flat.\n",
    "    \n",
    "    Input:\n",
    "        a1 [double]: present parameter value\n",
    "        \n",
    "    Return:\n",
    "        a2 [double]: next parameter value\n",
    "    '''\n",
    "    a2c   = np.random.uniform(low=-3.0, high=3.0, size=1)[0]\n",
    "    alpha = acceptance_prob(a2c, a1)\n",
    "\n",
    "    draw  = np.random.rand(1)[0]\n",
    "    if draw <= alpha:\n",
    "        return a2c\n",
    "    else:\n",
    "        return a1\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d08a3f",
   "metadata": {},
   "source": [
    "#### 3.3.3 Testing out how it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17efbd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing with 100 samplers, uniforming distributing between [-3, 3]\n",
    "num_samplers = 500\n",
    "samplers     = np.random.uniform(low=-3.0, high=3.0, size=num_samplers)\n",
    "new_samplers = np.zeros(num_samplers)\n",
    "all_samplers = samplers\n",
    "\n",
    "# how many iterations to advance the samplers\n",
    "num_itr = 0\n",
    "\n",
    "\n",
    "# Initializing plots\n",
    "fig = plt.figure(\n",
    "                 figsize = (8, 6)\n",
    "                )\n",
    "ax = fig.add_axes([0.12, 0.1, 0.75, 0.75])\n",
    "\n",
    "# Set the x/y axis title and legend\n",
    "plt.xlabel('x-axis [arbitrary unit]', size = 14.0)\n",
    "plt.ylabel('probability [arbitrary unit]', size = 14.0)\n",
    "\n",
    "plt.xscale('linear')\n",
    "plt.yscale('linear')\n",
    "plt.rc('font', size=14.0)          # controls default text sizes\n",
    "plt.rc('xtick', labelsize=14.0)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=14.0)    # fontsize of the tick labels\n",
    "\n",
    "# plotting the probability model\n",
    "a = np.arange(-3, 3, 0.05)\n",
    "y = np.zeros(len(a))\n",
    "for i in range(0, len(a)):\n",
    "    y[i] = mexhat(a[i])\n",
    "\n",
    "plt.plot(a, y/np.max(y), '-',\n",
    "         color = (0.4, 0.4, 1, 1), linewidth = 2.0,\n",
    "         label = 'Mexican hat model'\n",
    "        )\n",
    "\n",
    "# producing histogram of the samplers\n",
    "n_bin = 50\n",
    "hist, bin_edges = np.histogram(all_samplers, bins=n_bin)\n",
    "print(len(bin_edges))\n",
    "bin_centers = np.zeros(n_bin)\n",
    "for i in range(0, n_bin):\n",
    "    bin_centers[i] = (bin_edges[i] + bin_edges[i+1])/2.0\n",
    "    \n",
    "# plotting a histogram of all samplers\n",
    "plt.plot(bin_centers, hist/np.max(hist), '-',\n",
    "         color = (1.0, 0.4, 0.2, 1), linewidth = 2.0,\n",
    "         label = 'Initial distribution of samplers'\n",
    "        )\n",
    "    \n",
    "# Setting the figure legend \n",
    "plt.xlim( (-6, 3) )\n",
    "plt.legend(loc=2, fontsize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3004c06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing with 100 samplers, uniforming distributing between [-3, 3]\n",
    "num_samplers = 500\n",
    "samplers     = np.random.uniform(low=-3.0, high=3.0, size=num_samplers)\n",
    "new_samplers = np.zeros(num_samplers)\n",
    "all_samplers = samplers\n",
    "\n",
    "# how many iterations to advance the samplers\n",
    "num_itr = 50\n",
    "\n",
    "\n",
    "# Initializing plots\n",
    "fig = plt.figure(\n",
    "                 figsize = (8, 6)\n",
    "                )\n",
    "ax = fig.add_axes([0.12, 0.1, 0.75, 0.75])\n",
    "\n",
    "# Set the x/y axis title and legend\n",
    "plt.xlabel('x-axis [arbitrary unit]', size = 14.0)\n",
    "plt.ylabel('probability [arbitrary unit]', size = 14.0)\n",
    "\n",
    "plt.xscale('linear')\n",
    "plt.yscale('linear')\n",
    "plt.rc('font', size=14.0)          # controls default text sizes\n",
    "plt.rc('xtick', labelsize=14.0)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=14.0)    # fontsize of the tick labels\n",
    "\n",
    "# plotting the probability model\n",
    "a = np.arange(-3, 3, 0.05)\n",
    "y = np.zeros(len(a))\n",
    "for i in range(0, len(a)):\n",
    "    y[i] = mexhat(a[i])\n",
    "\n",
    "plt.plot(a, y/np.max(y), '-',\n",
    "         color = (0.4, 0.4, 1, 1), linewidth = 2.0,\n",
    "         label = 'Mexican hat model'\n",
    "        )\n",
    "\n",
    "# Advancing samplers\n",
    "for i in range(0, num_itr):\n",
    "    for j in range(0, num_samplers):\n",
    "        new_samplers[j] = metropolis_hasting_flatproposal( samplers[j] )\n",
    "    all_samplers = np.append(all_samplers, new_samplers)\n",
    "    samplers = new_samplers\n",
    "\n",
    "# producing histogram of the samplers\n",
    "n_bin = 50\n",
    "hist, bin_edges = np.histogram(all_samplers, bins=n_bin)\n",
    "print(len(bin_edges))\n",
    "bin_centers = np.zeros(n_bin)\n",
    "for i in range(0, n_bin):\n",
    "    bin_centers[i] = (bin_edges[i] + bin_edges[i+1])/2.0\n",
    "    \n",
    "# plotting a histogram of all samplers\n",
    "plt.plot(bin_centers, hist/np.max(hist), '-',\n",
    "         color = (1.0, 0.4, 0.2, 1), linewidth = 2.0,\n",
    "         label = 'Distribution of samplers with ' + str(num_itr) + ' iterations'\n",
    "        )\n",
    "    \n",
    "# Setting the figure legend \n",
    "plt.xlim( (-6, 3) )\n",
    "plt.legend(loc=2, fontsize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f720019b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing with 100 samplers, uniforming distributing between [-3, 3]\n",
    "num_samplers = 500\n",
    "samplers     = np.random.uniform(low=-3.0, high=3.0, size=num_samplers)\n",
    "new_samplers = np.zeros(num_samplers)\n",
    "all_samplers = samplers\n",
    "\n",
    "# how many iterations to advance the samplers\n",
    "num_itr = 500\n",
    "\n",
    "\n",
    "# Initializing plots\n",
    "fig = plt.figure(\n",
    "                 figsize = (8, 6)\n",
    "                )\n",
    "ax = fig.add_axes([0.12, 0.1, 0.75, 0.75])\n",
    "\n",
    "# Set the x/y axis title and legend\n",
    "plt.xlabel('x-axis [arbitrary unit]', size = 14.0)\n",
    "plt.ylabel('probability [arbitrary unit]', size = 14.0)\n",
    "\n",
    "plt.xscale('linear')\n",
    "plt.yscale('linear')\n",
    "plt.rc('font', size=14.0)          # controls default text sizes\n",
    "plt.rc('xtick', labelsize=14.0)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=14.0)    # fontsize of the tick labels\n",
    "\n",
    "# plotting the probability model\n",
    "a = np.arange(-3, 3, 0.05)\n",
    "y = np.zeros(len(a))\n",
    "for i in range(0, len(a)):\n",
    "    y[i] = mexhat(a[i])\n",
    "\n",
    "plt.plot(a, y/np.max(y), '-',\n",
    "         color = (0.4, 0.4, 1, 1), linewidth = 2.0,\n",
    "         label = 'Mexican hat model'\n",
    "        )\n",
    "\n",
    "# Advancing samplers\n",
    "for i in range(0, num_itr):\n",
    "    for j in range(0, num_samplers):\n",
    "        new_samplers[j] = metropolis_hasting_flatproposal( samplers[j] )\n",
    "    all_samplers = np.append(all_samplers, new_samplers)\n",
    "    samplers = new_samplers\n",
    "\n",
    "# producing histogram of the samplers\n",
    "n_bin = 50\n",
    "hist, bin_edges = np.histogram(all_samplers, bins=n_bin)\n",
    "print(len(bin_edges))\n",
    "bin_centers = np.zeros(n_bin)\n",
    "for i in range(0, n_bin):\n",
    "    bin_centers[i] = (bin_edges[i] + bin_edges[i+1])/2.0\n",
    "    \n",
    "# plotting a histogram of all samplers\n",
    "plt.plot(bin_centers, hist/np.max(hist), '-',\n",
    "         color = (1.0, 0.4, 0.2, 1), linewidth = 2.0,\n",
    "         label = 'Distribution of samplers with ' + str(num_itr) + ' iterations'\n",
    "        )\n",
    "    \n",
    "# Setting the figure legend \n",
    "plt.xlim( (-6, 3) )\n",
    "plt.legend(loc=2, fontsize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67246105",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing with 100 samplers, uniforming distributing between [-3, 3]\n",
    "num_samplers = 500\n",
    "samplers     = np.random.uniform(low=-3.0, high=3.0, size=num_samplers)\n",
    "new_samplers = np.zeros(num_samplers)\n",
    "all_samplers = np.zeros(num_samplers)\n",
    "\n",
    "# how many iterations to advance the samplers\n",
    "num_itr = 5000\n",
    "\n",
    "\n",
    "# Initializing plots\n",
    "fig = plt.figure(\n",
    "                 figsize = (8, 6)\n",
    "                )\n",
    "ax = fig.add_axes([0.12, 0.1, 0.75, 0.75])\n",
    "\n",
    "# Set the x/y axis title and legend\n",
    "plt.xlabel('x-axis [arbitrary unit]', size = 14.0)\n",
    "plt.ylabel('probability [arbitrary unit]', size = 14.0)\n",
    "\n",
    "plt.xscale('linear')\n",
    "plt.yscale('linear')\n",
    "plt.rc('font', size=14.0)          # controls default text sizes\n",
    "plt.rc('xtick', labelsize=14.0)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=14.0)    # fontsize of the tick labels\n",
    "\n",
    "# plotting the probability model\n",
    "a = np.arange(-3, 3, 0.05)\n",
    "y = np.zeros(len(a))\n",
    "for i in range(0, len(a)):\n",
    "    y[i] = mexhat(a[i])\n",
    "\n",
    "plt.plot(a, y/np.max(y), '-',\n",
    "         color = (0.4, 0.4, 1, 1), linewidth = 2.0,\n",
    "         label = 'Mexican hat model'\n",
    "        )\n",
    "\n",
    "# Advancing samplers\n",
    "for i in range(0, num_itr):\n",
    "    for j in range(0, num_samplers):\n",
    "        new_samplers[j] = metropolis_hasting_flatproposal( samplers[j] )\n",
    "    if i == 1000:\n",
    "        all_samplers = new_samplers\n",
    "    elif i > 1000:\n",
    "        all_samplers = np.append(all_samplers, new_samplers)\n",
    "    samplers = new_samplers\n",
    "\n",
    "# producing histogram of the samplers\n",
    "n_bin = 50\n",
    "hist, bin_edges = np.histogram(all_samplers, bins=n_bin)\n",
    "print(len(bin_edges))\n",
    "bin_centers = np.zeros(n_bin)\n",
    "for i in range(0, n_bin):\n",
    "    bin_centers[i] = (bin_edges[i] + bin_edges[i+1])/2.0\n",
    "    \n",
    "# plotting a histogram of all samplers\n",
    "plt.plot(bin_centers, hist/np.max(hist), '-',\n",
    "         color = (1.0, 0.4, 0.2, 1), linewidth = 2.0,\n",
    "         label = 'Distribution of samplers from 1000 to 5000 iterations'\n",
    "        )\n",
    "    \n",
    "# Setting the figure legend \n",
    "plt.xlim( (-6, 3) )\n",
    "plt.legend(loc=2, fontsize=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb88a58",
   "metadata": {},
   "source": [
    "### 3.2 MCMC fitting of the 1D polynomial model\n",
    "y = ax + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac2add8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the package for MCMC fittings\n",
    "import emcee, corner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6136c5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# allow using multiple processors\n",
    "from multiprocessing import Pool\n",
    "from multiprocessing import cpu_count\n",
    "\n",
    "num_cpu = cpu_count()\n",
    "print(\"You have {0} Processors\".format(num_cpu))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4027586",
   "metadata": {},
   "source": [
    "#### 3.2.1 Definining functions that are required in the MCMC model fittings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9facab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_prior(parms):\n",
    "    '''\n",
    "    Here is basically flat priors over the range [-1e10, 1e10] for both parameters.\n",
    "    \n",
    "    Input:\n",
    "        parms [numpy array] : the input variables for the model function.\n",
    "        \n",
    "    Return:\n",
    "        prob [double] : logged \"prior\" probability\n",
    "    '''\n",
    "    a, b = parms\n",
    "    if (-1e10 < a < 1e10) and \\\n",
    "       (-1e10 < b < 1e10):\n",
    "        return 0.0\n",
    "    \n",
    "    return -np.inf\n",
    "\n",
    "\n",
    "def log_likelihood(parms, x, y, y_err):\n",
    "    '''\n",
    "    This is the likelihood function.\n",
    "    \n",
    "    Input:\n",
    "        parms [numpy array] : the input variables for the model function.\n",
    "        x [numpy array] : x-coordinate values\n",
    "        y [numpy array] : y-coordinate values\n",
    "        yerr [numpy array] : standard measurement errors of y\n",
    "    '''\n",
    "    a, b  = parms\n",
    "    ymodel = myline(x, a, b)\n",
    "    \n",
    "    ln_likelihood = -0.5 * chisquare(y, y_err, ymodel)\n",
    "    \n",
    "    return ln_likelihood\n",
    "\n",
    "\n",
    "def log_probability(parms, x, y, yerr):\n",
    "    '''\n",
    "    This is the log probability function.\n",
    "    \n",
    "    Input:\n",
    "        parms [numpy array] : the input variables for the model function.\n",
    "        x [numpy array] : x-coordinate values\n",
    "        y [numpy array] : y-coordinate values\n",
    "        yerr [numpy array] : standard measurement errors of y\n",
    "    '''\n",
    "    \n",
    "    lp = log_prior(parms)\n",
    "    if not np.isfinite(lp):\n",
    "        return -np.inf\n",
    "    \n",
    "    return lp + log_likelihood(parms, x, y, yerr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72bb617",
   "metadata": {},
   "source": [
    "#### 3.2.2 Doing the MCMC fittings\n",
    "check [this page](https://emcee.readthedocs.io/en/stable/tutorials/parallel/) for how to parallelize this part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2abe109b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data from csv file\n",
    "path = './'\n",
    "filename = 'data_1dpoly.csv'\n",
    "df_read = pd.read_csv(path + filename)\n",
    "\n",
    "# model setup\n",
    "init_parms   = np.array( [999.0, 999.0] )\n",
    "ndim         = len(init_parms)\n",
    "\n",
    "# MCMC setup\n",
    "nwalkers        = 100  # number of walkers, which need to be a few times larger than the number of free-parameters\n",
    "nsteps          = 5000 # number of steps\n",
    "step_to_discard = 100  # number of steps to be discarded\n",
    "\n",
    "# initialize walkers at different positions (i.e., initial parameters)\n",
    "pos = init_parms + np.random.randn(nwalkers, ndim ) * 300\n",
    "\n",
    "# timing the code\n",
    "start_time = time.time()\n",
    "\n",
    "# running MCMC with a single CPU processor\n",
    "\n",
    "# initializing the emcee samplers\n",
    "sampler = emcee.EnsembleSampler(\n",
    "                                nwalkers, ndim, log_probability, \n",
    "                                args=(df_read.x, df_read.y, df_read.y_err)\n",
    "                                )\n",
    "\n",
    "\n",
    "# advancing the emcee samplers\n",
    "sampler.run_mcmc(\n",
    "                 pos, nsteps, progress = True\n",
    "                )\n",
    "\n",
    "# timing the code\n",
    "end_time = time.time()\n",
    "print(\"Time taken:\", end_time - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0238c701",
   "metadata": {},
   "source": [
    "#### 3.2.3 Plotting saplers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab82f1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, figsize=(10, 7), sharex=True)\n",
    "\n",
    "samples = sampler.get_chain()\n",
    "num_samples = len(samples)\n",
    "\n",
    "labels = [\"a\", \"b\"]\n",
    "\n",
    "for i in range(ndim):\n",
    "    ax = axes[i]\n",
    "    ax.plot(\n",
    "            samples[:, :, i], \n",
    "            \"k\", \n",
    "            alpha=0.3\n",
    "           )\n",
    "    ax.set_xlim(0, len(samples))\n",
    "    ax.set_ylabel(labels[i])\n",
    "\n",
    "axes[-1].set_xlabel(\"step number\");\n",
    "\n",
    "# Setting plotting ranges\n",
    "ax.set_xlim(step_to_discard, num_samples)\n",
    "axes[0].set_ylim(0, 20)\n",
    "axes[1].set_ylim(0, 200)\n",
    "\n",
    "# PDF file output\n",
    "plt.savefig('emcee_modeldata_1dpoly.pdf', \n",
    "            transparent = True\n",
    "           )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb978ef",
   "metadata": {},
   "source": [
    "#### 3.2.4 Making corner plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af70e198",
   "metadata": {},
   "outputs": [],
   "source": [
    "import corner\n",
    "\n",
    "flat_samples = sampler.get_chain(\n",
    "                                 discard = step_to_discard, \n",
    "                                 #thin = 15, \n",
    "                                 flat = True\n",
    "                                )\n",
    "\n",
    "\n",
    "fig = corner.corner(\n",
    "                    flat_samples, labels = labels, truths=[a_true, b_true]\n",
    "                   )\n",
    "\n",
    "# PDF file output\n",
    "plt.savefig('emcee_corner_1dpoly.pdf', \n",
    "            transparent = True\n",
    "           )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55994b5",
   "metadata": {},
   "source": [
    "#### 3.2.5 Summarizing the results of MCMC fittings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9e887a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mcmc_a = np.percentile(flat_samples[:, 0], [16, 50, 84])\n",
    "q      = np.diff(mcmc_a)\n",
    "print('a value is: ' + str(round(mcmc_a[1],2) ) + '-' + str(round(q[0],2) ) +  '/+' + str( round(q[1], 2) ))\n",
    "\n",
    "mcmc_b = np.percentile(flat_samples[:, 1], [16, 50, 84])\n",
    "q      = np.diff(mcmc_b)\n",
    "print('b value is: ' + str(round(mcmc_b[1],2) ) + '-' + str(round(q[0],2) ) +  '/+' + str( round(q[1], 2) ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c62b47",
   "metadata": {},
   "source": [
    "#### 3.2.6 Plotting the MCMC fitting results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6c2589",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing Figure ############################################\n",
    "fig = plt.figure(\n",
    "                 figsize = (8, 8)\n",
    "                )\n",
    "ax = fig.add_axes([0.12, 0.1, 0.75, 0.75])\n",
    "\n",
    "# Set the x/y axis title and legend\n",
    "plt.xlabel('x-axis [arbitrary unit]', size = 14.0)\n",
    "plt.ylabel('y-axis [arbitrary unit]', size = 14.0)\n",
    "\n",
    "plt.xscale('linear')\n",
    "plt.yscale('linear')\n",
    "#plt.xscale('linear')\n",
    "#plt.yscale('linear')\n",
    "plt.rc('font', size=14.0)          # controls default text sizes\n",
    "plt.rc('xtick', labelsize=14.0)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=14.0)    # fontsize of the tick labels\n",
    "##################################################################\n",
    "\n",
    "# label chi-square\n",
    "chi2 = chisquare(df_read.y, df_read.y_err, myline(df_read.x, mcmc_a[1], mcmc_b[1] ) )\n",
    "label_string = 'Chi-square: ' + str( round(chi2, 2) )\n",
    "plt.text(0.33, 0.15, \n",
    "         label_string,\n",
    "         color = (0.1, 0.3, 0.7, 0.7),\n",
    "         verticalalignment = 'bottom', horizontalalignment = 'left',\n",
    "         transform = ax.transAxes,\n",
    "         fontsize=14)\n",
    "\n",
    "# plot data\n",
    "plt.plot(df_read.x, df_read.y,\n",
    "         'o', markersize = 2.0,\n",
    "         color = (0.7, 0.3, 0.3, 0.7),\n",
    "         label = \"Randomly realized linear model\"\n",
    "        )\n",
    "\n",
    "# plot model\n",
    "x_sort = np.sort(df_read.x)\n",
    "plt.plot(x_sort, myline(x_sort, mcmc_a[1], mcmc_b[1]),\n",
    "         '-', linewidth = 2.0,\n",
    "         color = (0.1, 0.3, 0.7, 0.7),\n",
    "         label = \"Best-fit model with MCMC\"\n",
    "        )\n",
    "\n",
    "# text labeling\n",
    "label_string = 'best-fit: y = ' + str( round(mcmc_a[1], 2) ) + 'x' + \\\n",
    "                              ' +' + str( round(mcmc_b[1], 2) )\n",
    "plt.text(0.35, 0.2, # location of the text label\n",
    "         label_string, # content of the label\n",
    "         color = (0.1, 0.3, 0.7, 0.7),\n",
    "         verticalalignment = 'bottom', horizontalalignment = 'left',\n",
    "         transform = ax.transAxes, # use relative coordinates\n",
    "         fontsize=14)\n",
    "\n",
    "# Setting the figure legend \n",
    "plt.legend(loc=2, fontsize=12)\n",
    "\n",
    "# PDF file output\n",
    "plt.savefig('MCMC_modeldata_1dpoly.pdf', \n",
    "            transparent = True\n",
    "           )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a176a02",
   "metadata": {},
   "source": [
    "#### 3.2.7 Using Multi-Processor\n",
    "This is a bad example since the evaluation of the probability functions is too simple.\n",
    "Therefore, the data transfer becomes the bottleneck, making the multi-processing calculation taking longer time than the single-processor calculation. But You can take this part as an example of how to setup the codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee5581e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the module that defines the log probability and likelihood\n",
    "import lecture_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510d923e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you are using Macbook Pro, the following import is necessary\n",
    "# and we must use the HDF backend\n",
    "from emcee.backends import HDFBackend\n",
    "\n",
    "n_cpu = cpu_count()\n",
    "print(\"You have {0} CPUs processors\".format(n_cpu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb27677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data from csv file\n",
    "path = './'\n",
    "filename = 'data_1dpoly.csv'\n",
    "df_read = pd.read_csv(path + filename)\n",
    "\n",
    "# model setup\n",
    "init_parms   = np.array( [999.0, 999.0] )\n",
    "ndim         = len(init_parms)\n",
    "\n",
    "# MCMC setup\n",
    "nwalkers        = 100   # number of walkers, which need to be a few times larger than the number of free-parameters\n",
    "nsteps          = 5000  # number of steps\n",
    "step_to_discard = 100   # number of steps to be discarded\n",
    "n_processor     = 7     # number of CPU processors to use\n",
    "\n",
    "# initialize walkers at different positions (i.e., initial parameters)\n",
    "pos = init_parms + np.random.randn(nwalkers, ndim ) * 300\n",
    "\n",
    "# timing the code\n",
    "start_time = time.time()\n",
    "\n",
    "# running MCMC with multi-processor\n",
    "if n_processor < n_cpu:\n",
    "    # initializing the emcee samplers\n",
    "    backend_name = 'backend.h5'\n",
    "    os.system('rm -rf ' + backend_name)\n",
    "    mcmcbackend = HDFBackend(filename = backend_name)\n",
    "    pool = Pool(processes = n_processor)\n",
    "    sampler = emcee.EnsembleSampler(\n",
    "                                    nwalkers, ndim, lecture_module.log_probability, \n",
    "                                    args    = (df_read.x, df_read.y, df_read.y_err),\n",
    "                                    backend = mcmcbackend,\n",
    "                                    pool    = pool      # Multi-processor (does not work for Macbook Pro)\n",
    "                                   )\n",
    "    # advancing the emcee samplers\n",
    "    sampler.run_mcmc(\n",
    "                     pos, nsteps, progress = True\n",
    "                    )\n",
    "else:\n",
    "    print('Dumb axx, you got a bug with Pool setting.')\n",
    "\n",
    "# timing the code\n",
    "end_time = time.time()\n",
    "print(\"Time taken:\", end_time - start_time)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
